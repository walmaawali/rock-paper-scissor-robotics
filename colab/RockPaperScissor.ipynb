{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Paper Rock Sessiors\n",
        "This notebook is using Python Tensorflow/Keras to build a Convolution Neural Network (CNN) to classify an image of human hand into \"Paper\", \"Rock\", or \"Scissors\".\n",
        "\n",
        "How to use the notebook:\n",
        "1.   Upload the dataset of images to the notebook Files.\n",
        "2.   Make sure the machine is running with GPU. \n",
        "Go to *Runtime > Change Runtime Type >  Hardware Acceleration > GPU*\n",
        "3.   Run each code block in sequence\n",
        "\n",
        "Happy coding ðŸ¦¾"
      ],
      "metadata": {
        "id": "breuI8J7kQz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip rps.zip -d /content/rps"
      ],
      "metadata": {
        "id": "U2WTIO0qx-Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za6AQU0tkKON"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "rock_dir = \"/content/rps/train/rock\"\n",
        "paper_dir = \"/content/rps/train/paper\"\n",
        "scissors_dir = \"/content/rps/train/scissors\"\n",
        "\n",
        "# Printing the number of images in each folder (for double checking)\n",
        "print(len(os.listdir(rock_dir)))\n",
        "print(len(os.listdir(paper_dir)))\n",
        "print(len(os.listdir(scissors_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Setting a data augmetation generator for training\n",
        "train_dir = \"/content/rps/train\"\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, \\\n",
        "                                   rotation_range=90, \\\n",
        "                                   width_shift_range=0.2, \\\n",
        "                                   height_shift_range=0.2, \\\n",
        "                                   shear_range=0.1, \\\n",
        "                                   zoom_range=0.2, \\\n",
        "                                   horizontal_flip=True, \\\n",
        "                                   fill_mode='nearest', \\\n",
        "                                   brightness_range=(0.3,0.7)\n",
        "                                   )\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150,150), \\\n",
        "                                                    batch_size=20, class_mode=\"categorical\", color_mode='grayscale')\n",
        "\n",
        "# Setting a data generator for validation data\n",
        "valid_dir = \"/content/rps/valid\"\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "valid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(150,150), \\\n",
        "                                                    batch_size=20, class_mode=\"categorical\", color_mode='grayscale')\n",
        "\n",
        "# Setting a data generator for testing data\n",
        "test_dir = \"/content/rps/test\"\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(150,150), \\\n",
        "                                                    batch_size=20, class_mode=\"categorical\", color_mode='grayscale')"
      ],
      "metadata": {
        "id": "7LrEIfBEkxvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting sample of the training images\n",
        "# Note: you can save the image by right-clicking on it\n",
        "import matplotlib.pyplot as plt\n",
        "x_batch, y_batch = next(train_generator)\n",
        "f, axarr = plt.subplots(4,4, figsize=(12, 12))\n",
        "for i in range(4):\n",
        "  for j in range(4):\n",
        "    image = x_batch[i*4+j]\n",
        "    axarr[i,j].imshow(image,cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HHNVDyjJsBzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code will create the model\n",
        "# You can add more layers, change the number of filters (kernals), \n",
        "# and improve the accuracy!\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def create_model():\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # Layer 1: Convolution with 64 filters (3x3) followed by Max Polling layer\n",
        "  model.add(layers.Conv2D(64, (3,3), input_shape=(150,150,1), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D())\n",
        "\n",
        "  # Layer 2: Convolution with 64 filters (3x3) followed by Max Polling layer\n",
        "  model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D())\n",
        "\n",
        "  # Layer 3: Convolution with 128 filters (3x3) followed by Max Polling layer\n",
        "  model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D())\n",
        "\n",
        "  # Layer 4: Convolution with 128 filters (3x3) followed by Max Polling layer\n",
        "  model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D())\n",
        "\n",
        "  # Layer 5: Fully connected Layer\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "  # Layer 6: Output Layer\n",
        "  model.add(layers.Dense(3, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "# Print a summary about the model (for double checking)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9HhnEN1hk84q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training for 15 epochs (you can choose less or more epochs)\n",
        "model.compile(optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "hist = model.fit(train_generator, epochs=15, validation_data=valid_generator)"
      ],
      "metadata": {
        "id": "5vTWRU6KlLVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training accuracy VS validation accuracy\n",
        "# The model performs well if both are increasing together\n",
        "# The model performs bad if the validation accuracy drops\n",
        "# Note: you can save the image by right-clicking on it\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = hist.history['acc']\n",
        "val_acc = hist.history['val_acc']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, label=\"training accuracy\")\n",
        "plt.plot(epochs, val_acc, label = \"validation accuracy\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y4I4wF2MlPJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(test_generator)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "metadata": {
        "id": "4RwUvWAongVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('models/rps_model')"
      ],
      "metadata": {
        "id": "115HeMR5FQ8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
        "\n",
        "# define the directory for .pb model\n",
        "pb_model_path = \"/content\"\n",
        "# define the name of .pb model\n",
        "pb_model_name = \"rps_model.pb\"\n",
        "# create directory for further converted model\n",
        "os.makedirs(pb_model_path, exist_ok=True)\n",
        "# get model TF graph\n",
        "tf_model_graph = tf.function(lambda x: model(x))\n",
        "# get concrete function\n",
        "tf_model_graph = tf_model_graph.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
        "# obtain frozen concrete function\n",
        "frozen_tf_func = convert_variables_to_constants_v2(tf_model_graph)\n",
        "# get frozen graph\n",
        "frozen_tf_func.graph.as_graph_def()\n",
        "# save full tf model\n",
        "tf.io.write_graph(graph_or_graph_def=frozen_tf_func.graph,\n",
        "                  logdir=pb_model_path,\n",
        "                  name=pb_model_name,\n",
        "                  as_text=False)"
      ],
      "metadata": {
        "id": "rYpbEgLjMgak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "model = tf.keras.models.load_model('rps.h5')\n",
        "#model.summary()\n",
        "\n",
        "img = cv2.imread(\"/content/rps/valid/rock/testrock01-00_png.rf.9fb3b294595cff53ba76bef13e210814.jpg\")\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img = img/255.0\n",
        "\n",
        "img = cv2.resize(img, (150,150))\n",
        "plt.imshow(img, cmap='gray')\n",
        "img = np.expand_dims(img, axis=0) # image shape is (1,150,150,1)\n",
        "#print(img.shape)\n",
        "target = np.array([[0,1,0]])\n",
        "#print(target.shape)\n",
        "\n",
        "output = model.predict(img, verbose=False)\n",
        "imagenet_class_id = np.argmax(output)\n",
        "imagenet_labels = ['Paper', \"Rock\", \"Scissor\"]\n",
        "print(imagenet_labels[imagenet_class_id])\n",
        "loss, acc = model.evaluate(img, target, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
      ],
      "metadata": {
        "id": "YoUVPem79Fa7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}